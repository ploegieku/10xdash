{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwir9QYQtgDok9haQDttE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olgabot/10xdash/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCPz3mqfEHPE",
        "outputId": "8ec2494a-0ed7-4388-c7c0-41631bbe05fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 04:22:47--  https://raw.githubusercontent.com/olgabot/2023-beyonce-gpt/main/assets/beyonce_lyrics.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 361820 (353K) [text/plain]\n",
            "Saving to: ‘beyonce_lyrics.txt’\n",
            "\n",
            "beyonce_lyrics.txt  100%[===================>] 353.34K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-12-11 04:22:47 (50.9 MB/s) - ‘beyonce_lyrics.txt’ saved [361820/361820]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/olgabot/2023-beyonce-gpt/main/assets/beyonce_lyrics.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('beyonce_lyrics.txt') as f:\n",
        "  text = f.read()\n",
        "print(f\"Length of dataset in characters: {len(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANoEuKKsFNq4",
        "outputId": "be70b335-4d9c-4653-f4de-752fa3d0dc0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters: 361564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSsZ1nGfFVMO",
        "outputId": "b57359b8-9bd3-4bae-af55-1abb622985d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Crazy In Love\"\n",
            "(feat. Jay-Z)\n",
            "\n",
            "Yes! So crazy right now!\n",
            "Most incredibly, it's your girl, B\n",
            "It's your boy, Young\n",
            "You ready?\n",
            "\n",
            "Oh oh, oh oh, oh oh, oh no no (Oww!)\n",
            "Oh oh, oh oh, oh oh, oh no no\n",
            "Oh oh, oh oh, oh oh, oh no no\n",
            "Oh oh, oh oh, oh oh, oh no no\n",
            "\n",
            "Geah! History in the making\n",
            "Part two!\n",
            "It's so crazy right now\n",
            "\n",
            "I look and stare so deep in your eyes (I)\n",
            "I touch on you more and more every time\n",
            "When you leave, I'm begging you not to go\n",
            "Call your name, two, three times in a row\n",
            "Such a funny thing for me to try to explain\n",
            "How I'm feeling, and my pride is the one to blame (Yeah)\n",
            "'Cause I know I don't understand\n",
            "Just how your love can do what no one else can\n",
            "\n",
            "Got me looking so crazy right now\n",
            "Your love's got me looking so crazy right now (Your love)\n",
            "Got me looking so crazy right now\n",
            "Your touch got me looking so crazy right now (Your touch)\n",
            "Got me hoping you'll page me right now (Hey)\n",
            "Your kiss got me hoping you'll save me right now\n",
            "Looking so crazy, your love's got me looking\n",
            "Got me looking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Characters in the text\n",
        "chars = sorted(set(list(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFVkGhBcFYCu",
        "outputId": "cdea6b8a-00df-46e7-f285-d4b61edb4afa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"&'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz¿Éàáâçèéêíïñóúɔɛɲ̀ẹỌọ–—\n",
            "103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --> Interesting, there's more than just English letters here, but some other languages, too\n"
      ],
      "metadata": {
        "id": "SxIGNHpQH8wU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map characters to integers\n",
        "\n",
        "s_to_i = {ch: i for i, ch in enumerate(chars)}\n",
        "i_to_s = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encoder: Take a string and convert it to integers\n",
        "encode = lambda s: [s_to_i[c] for c in s]\n",
        "\n",
        "# Decoder: Given a liste of integers, convert it to strings\n",
        "decode = lambda l: ''.join(i_to_s[i] for i in l)\n",
        "\n",
        "print(encode('hii there'))\n",
        "print(decode(encode('hii there')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Aows26FlCg",
        "outputId": "fa3eaa87-ba84-4357-802f-c28476de6e9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[61, 62, 62, 1, 73, 61, 58, 71, 58]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrmY0xBSGcJm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)"
      ],
      "metadata": {
        "id": "DQhnQIfjHM02"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXSjtfJNHSP4",
        "outputId": "1103e8e0-46e9-46df-b138-7d53b8d8921c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([361564]) torch.int64\n",
            "tensor([ 3, 28, 71, 54, 79, 78,  1, 34, 67,  1, 37, 68, 75, 58,  3,  0,  6, 59,\n",
            "        58, 54, 73, 11,  1, 35, 54, 78, 10, 51,  7,  0,  0, 50, 58, 72,  2,  1,\n",
            "        44, 68,  1, 56, 71, 54, 79, 78,  1, 71, 62, 60, 61, 73,  1, 67, 68, 76,\n",
            "         2,  0, 38, 68, 72, 73,  1, 62, 67, 56, 71, 58, 57, 62, 55, 65, 78,  9,\n",
            "         1, 62, 73,  5, 72,  1, 78, 68, 74, 71,  1, 60, 62, 71, 65,  9,  1, 27,\n",
            "         0, 34, 73,  5, 72,  1, 78, 68, 74, 71,  1, 55, 68, 78,  9,  1, 50, 68,\n",
            "        74, 67, 60,  0, 50, 68, 74,  1, 71, 58, 54, 57, 78, 25,  0,  0, 40, 61,\n",
            "         1, 68, 61,  9,  1, 68, 61,  1, 68, 61,  9,  1, 68, 61,  1, 68, 61,  9,\n",
            "         1, 68, 61,  1, 67, 68,  1, 67, 68,  1,  6, 40, 76, 76,  2,  7,  0, 40,\n",
            "        61,  1, 68, 61,  9,  1, 68, 61,  1, 68, 61,  9,  1, 68, 61,  1, 68, 61,\n",
            "         9,  1, 68, 61,  1, 67, 68,  1, 67, 68,  0, 40, 61,  1, 68, 61,  9,  1,\n",
            "        68, 61,  1, 68, 61,  9,  1, 68, 61,  1, 68, 61,  9,  1, 68, 61,  1, 67,\n",
            "        68,  1, 67, 68,  0, 40, 61,  1, 68, 61,  9,  1, 68, 61,  1, 68, 61,  9,\n",
            "         1, 68, 61,  1, 68, 61,  9,  1, 68, 61,  1, 67, 68,  1, 67, 68,  0,  0,\n",
            "        32, 58, 54, 61,  2,  1, 33, 62, 72, 73, 68, 71, 78,  1, 62, 67,  1, 73,\n",
            "        61, 58,  1, 66, 54, 64, 62, 67, 60,  0, 41, 54, 71, 73,  1, 73, 76, 68,\n",
            "         2,  0, 34, 73,  5, 72,  1, 72, 68,  1, 56, 71, 54, 79, 78,  1, 71, 62,\n",
            "        60, 61, 73,  1, 67, 68, 76,  0,  0, 34,  1, 65, 68, 68, 64,  1, 54, 67,\n",
            "        57,  1, 72, 73, 54, 71, 58,  1, 72, 68,  1, 57, 58, 58, 69,  1, 62, 67,\n",
            "         1, 78, 68, 74, 71,  1, 58, 78, 58, 72,  1,  6, 34,  7,  0, 34,  1, 73,\n",
            "        68, 74, 56, 61,  1, 68, 67,  1, 78, 68, 74,  1, 66, 68, 71, 58,  1, 54,\n",
            "        67, 57,  1, 66, 68, 71, 58,  1, 58, 75, 58, 71, 78,  1, 73, 62, 66, 58,\n",
            "         0, 48, 61, 58, 67,  1, 78, 68, 74,  1, 65, 58, 54, 75, 58,  9,  1, 34,\n",
            "         5, 66,  1, 55, 58, 60, 60, 62, 67, 60,  1, 78, 68, 74,  1, 67, 68, 73,\n",
            "         1, 73, 68,  1, 60, 68,  0, 28, 54, 65, 65,  1, 78, 68, 74, 71,  1, 67,\n",
            "        54, 66, 58,  9,  1, 73, 76, 68,  9,  1, 73, 61, 71, 58, 58,  1, 73, 62,\n",
            "        66, 58, 72,  1, 62, 67,  1, 54,  1, 71, 68, 76,  0, 44, 74, 56, 61,  1,\n",
            "        54,  1, 59, 74, 67, 67, 78,  1, 73, 61, 62, 67, 60,  1, 59, 68, 71,  1,\n",
            "        66, 58,  1, 73, 68,  1, 73, 71, 78,  1, 73, 68,  1, 58, 77, 69, 65, 54,\n",
            "        62, 67,  0, 33, 68, 76,  1, 34,  5, 66,  1, 59, 58, 58, 65, 62, 67, 60,\n",
            "         9,  1, 54, 67, 57,  1, 66, 78,  1, 69, 71, 62, 57, 58,  1, 62, 72,  1,\n",
            "        73, 61, 58,  1, 68, 67, 58,  1, 73, 68,  1, 55, 65, 54, 66, 58,  1,  6,\n",
            "        50, 58, 54, 61,  7,  0,  5, 28, 54, 74, 72, 58,  1, 34,  1, 64, 67, 68,\n",
            "        76,  1, 34,  1, 57, 68, 67,  5, 73,  1, 74, 67, 57, 58, 71, 72, 73, 54,\n",
            "        67, 57,  0, 35, 74, 72, 73,  1, 61, 68, 76,  1, 78, 68, 74, 71,  1, 65,\n",
            "        68, 75, 58,  1, 56, 54, 67,  1, 57, 68,  1, 76, 61, 54, 73,  1, 67, 68,\n",
            "         1, 68, 67, 58,  1, 58, 65, 72, 58,  1, 56, 54, 67,  0,  0, 32, 68, 73,\n",
            "         1, 66, 58,  1, 65, 68, 68, 64, 62, 67, 60,  1, 72, 68,  1, 56, 71, 54,\n",
            "        79, 78,  1, 71, 62, 60, 61, 73,  1, 67, 68, 76,  0, 50, 68, 74, 71,  1,\n",
            "        65, 68, 75, 58,  5, 72,  1, 60, 68, 73,  1, 66, 58,  1, 65, 68, 68, 64,\n",
            "        62, 67, 60,  1, 72, 68,  1, 56, 71, 54, 79, 78,  1, 71, 62, 60, 61, 73,\n",
            "         1, 67, 68, 76,  1,  6, 50, 68, 74, 71,  1, 65, 68, 75, 58,  7,  0, 32,\n",
            "        68, 73,  1, 66, 58,  1, 65, 68, 68, 64, 62, 67, 60,  1, 72, 68,  1, 56,\n",
            "        71, 54, 79, 78,  1, 71, 62, 60, 61, 73,  1, 67, 68, 76,  0, 50, 68, 74,\n",
            "        71,  1, 73, 68, 74, 56, 61,  1, 60, 68, 73,  1, 66, 58,  1, 65, 68, 68,\n",
            "        64, 62, 67, 60,  1, 72, 68,  1, 56, 71, 54, 79, 78,  1, 71, 62, 60, 61,\n",
            "        73,  1, 67, 68, 76,  1,  6, 50, 68, 74, 71,  1, 73, 68, 74, 56, 61,  7,\n",
            "         0, 32, 68, 73,  1, 66, 58,  1, 61, 68, 69, 62, 67, 60,  1, 78, 68, 74,\n",
            "         5, 65, 65,  1, 69, 54, 60, 58,  1, 66, 58,  1, 71, 62, 60, 61, 73,  1,\n",
            "        67, 68, 76,  1,  6, 33, 58, 78,  7,  0, 50, 68, 74, 71,  1, 64, 62, 72,\n",
            "        72,  1, 60, 68, 73,  1, 66, 58,  1, 61, 68, 69, 62, 67, 60,  1, 78, 68,\n",
            "        74,  5, 65, 65,  1, 72, 54, 75, 58,  1, 66, 58,  1, 71, 62, 60, 61, 73,\n",
            "         1, 67, 68, 76,  0, 37, 68, 68, 64, 62, 67, 60,  1, 72, 68,  1, 56, 71,\n",
            "        54, 79, 78,  9,  1, 78, 68, 74, 71,  1, 65, 68, 75, 58,  5, 72,  1, 60,\n",
            "        68, 73,  1, 66, 58,  1, 65, 68, 68, 64, 62, 67, 60,  0, 32, 68, 73,  1,\n",
            "        66, 58,  1, 65, 68, 68, 64, 62, 67, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "1-zGSNA1HV6R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfFz31krIOsp",
        "outputId": "4f0f9431-9643-479c-8f19-0185a2b19405"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3, 28, 71, 54, 79, 78,  1, 34, 67])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJSwNUArIRck",
        "outputId": "e13a1cf5-4c5e-4b64-cee8-4a35545aac87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([3]) the target: 28\n",
            "when input is tensor([ 3, 28]) the target: 71\n",
            "when input is tensor([ 3, 28, 71]) the target: 54\n",
            "when input is tensor([ 3, 28, 71, 54]) the target: 79\n",
            "when input is tensor([ 3, 28, 71, 54, 79]) the target: 78\n",
            "when input is tensor([ 3, 28, 71, 54, 79, 78]) the target: 1\n",
            "when input is tensor([ 3, 28, 71, 54, 79, 78,  1]) the target: 34\n",
            "when input is tensor([ 3, 28, 71, 54, 79, 78,  1, 34]) the target: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(9481)\n",
        "\n",
        "# How many independent sequences to process in parallel?\n",
        "batch_size = 4\n",
        "\n",
        "# What is the maximum context length for predictions?\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  # Generate a small batch of data of inputs x and targets y\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix] )\n",
        "  return x, y\n",
        "\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "def decode_tensor(tensor):\n",
        "  # Don't iterate if the tensor is length 1\n",
        "  if len(tensor) == 1:\n",
        "    return decode(tensor.tolist())\n",
        "  else:\n",
        "    return decode(tensor.tolist())\n",
        "\n",
        "for b in range(batch_size):    # batch dimension\n",
        "  print('\\n- batch -')\n",
        "  for t in range(block_size):  # time dimension\n",
        "    print('--- time ---')\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b, t]\n",
        "    print(f\"when input is {context.tolist()}, the target: {target}\")\n",
        "\n",
        "\n",
        "    context_decoded = decode_tensor(context)\n",
        "    target_decoded = decode([target.tolist()])\n",
        "    print(f\"when input is '{context_decoded}', the target: '{target_decoded}'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdYkl_eXIfxG",
        "outputId": "23b82a4c-f367-46e5-c9e8-2c387d0255af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[71, 60, 58, 73,  1, 76, 61, 58],\n",
            "        [54, 72, 72,  1, 62, 73,  1, 68],\n",
            "        [57,  1, 78, 68, 74,  0, 30, 75],\n",
            "        [ 9,  1, 68, 64, 54, 78,  0, 40]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[60, 58, 73,  1, 76, 61, 58, 71],\n",
            "        [72, 72,  1, 62, 73,  1, 68, 59],\n",
            "        [ 1, 78, 68, 74,  0, 30, 75, 58],\n",
            "        [ 1, 68, 64, 54, 78,  0, 40, 64]])\n",
            "\n",
            "- batch -\n",
            "--- time ---\n",
            "when input is [71], the target: 60\n",
            "when input is 'r', the target: 'g'\n",
            "--- time ---\n",
            "when input is [71, 60], the target: 58\n",
            "when input is 'rg', the target: 'e'\n",
            "--- time ---\n",
            "when input is [71, 60, 58], the target: 73\n",
            "when input is 'rge', the target: 't'\n",
            "--- time ---\n",
            "when input is [71, 60, 58, 73], the target: 1\n",
            "when input is 'rget', the target: ' '\n",
            "--- time ---\n",
            "when input is [71, 60, 58, 73, 1], the target: 76\n",
            "when input is 'rget ', the target: 'w'\n",
            "--- time ---\n",
            "when input is [71, 60, 58, 73, 1, 76], the target: 61\n",
            "when input is 'rget w', the target: 'h'\n",
            "--- time ---\n",
            "when input is [71, 60, 58, 73, 1, 76, 61], the target: 58\n",
            "when input is 'rget wh', the target: 'e'\n",
            "--- time ---\n",
            "when input is [71, 60, 58, 73, 1, 76, 61, 58], the target: 71\n",
            "when input is 'rget whe', the target: 'r'\n",
            "\n",
            "- batch -\n",
            "--- time ---\n",
            "when input is [54], the target: 72\n",
            "when input is 'a', the target: 's'\n",
            "--- time ---\n",
            "when input is [54, 72], the target: 72\n",
            "when input is 'as', the target: 's'\n",
            "--- time ---\n",
            "when input is [54, 72, 72], the target: 1\n",
            "when input is 'ass', the target: ' '\n",
            "--- time ---\n",
            "when input is [54, 72, 72, 1], the target: 62\n",
            "when input is 'ass ', the target: 'i'\n",
            "--- time ---\n",
            "when input is [54, 72, 72, 1, 62], the target: 73\n",
            "when input is 'ass i', the target: 't'\n",
            "--- time ---\n",
            "when input is [54, 72, 72, 1, 62, 73], the target: 1\n",
            "when input is 'ass it', the target: ' '\n",
            "--- time ---\n",
            "when input is [54, 72, 72, 1, 62, 73, 1], the target: 68\n",
            "when input is 'ass it ', the target: 'o'\n",
            "--- time ---\n",
            "when input is [54, 72, 72, 1, 62, 73, 1, 68], the target: 59\n",
            "when input is 'ass it o', the target: 'f'\n",
            "\n",
            "- batch -\n",
            "--- time ---\n",
            "when input is [57], the target: 1\n",
            "when input is 'd', the target: ' '\n",
            "--- time ---\n",
            "when input is [57, 1], the target: 78\n",
            "when input is 'd ', the target: 'y'\n",
            "--- time ---\n",
            "when input is [57, 1, 78], the target: 68\n",
            "when input is 'd y', the target: 'o'\n",
            "--- time ---\n",
            "when input is [57, 1, 78, 68], the target: 74\n",
            "when input is 'd yo', the target: 'u'\n",
            "--- time ---\n",
            "when input is [57, 1, 78, 68, 74], the target: 0\n",
            "when input is 'd you', the target: '\n",
            "'\n",
            "--- time ---\n",
            "when input is [57, 1, 78, 68, 74, 0], the target: 30\n",
            "when input is 'd you\n",
            "', the target: 'E'\n",
            "--- time ---\n",
            "when input is [57, 1, 78, 68, 74, 0, 30], the target: 75\n",
            "when input is 'd you\n",
            "E', the target: 'v'\n",
            "--- time ---\n",
            "when input is [57, 1, 78, 68, 74, 0, 30, 75], the target: 58\n",
            "when input is 'd you\n",
            "Ev', the target: 'e'\n",
            "\n",
            "- batch -\n",
            "--- time ---\n",
            "when input is [9], the target: 1\n",
            "when input is ',', the target: ' '\n",
            "--- time ---\n",
            "when input is [9, 1], the target: 68\n",
            "when input is ', ', the target: 'o'\n",
            "--- time ---\n",
            "when input is [9, 1, 68], the target: 64\n",
            "when input is ', o', the target: 'k'\n",
            "--- time ---\n",
            "when input is [9, 1, 68, 64], the target: 54\n",
            "when input is ', ok', the target: 'a'\n",
            "--- time ---\n",
            "when input is [9, 1, 68, 64, 54], the target: 78\n",
            "when input is ', oka', the target: 'y'\n",
            "--- time ---\n",
            "when input is [9, 1, 68, 64, 54, 78], the target: 0\n",
            "when input is ', okay', the target: '\n",
            "'\n",
            "--- time ---\n",
            "when input is [9, 1, 68, 64, 54, 78, 0], the target: 40\n",
            "when input is ', okay\n",
            "', the target: 'O'\n",
            "--- time ---\n",
            "when input is [9, 1, 68, 64, 54, 78, 0, 40], the target: 64\n",
            "when input is ', okay\n",
            "O', the target: 'k'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfRLtHdYLAJy",
        "outputId": "ac5f7d52-b8cc-4477-a752-ed3807fc6a57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[71, 60, 58, 73,  1, 76, 61, 58],\n",
            "        [54, 72, 72,  1, 62, 73,  1, 68],\n",
            "        [57,  1, 78, 68, 74,  0, 30, 75],\n",
            "        [ 9,  1, 68, 64, 54, 78,  0, 40]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start writing the bigram langage model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(9481)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    # Each token reads off of the logits (scores) for the next token from a lookup table\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "\n",
        "    # idx and targets are both (B, T) tensor of integers\n",
        "    logits = self.token_embedding_table(idx) # (B, T, C)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      # Rershape logits\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "\n",
        "      targets = targets.view(B*T)\n",
        "\n",
        "      # Measures quality of next character given previous character\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    # idx is a (B, T) array of indices in the current context\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "      # Do predictions\n",
        "      logits, loss = self(idx)\n",
        "\n",
        "      # Focus only on the last time step\n",
        "      logits = logits[:, -1, :] # -> becomes (B, C)\n",
        "\n",
        "      # Apply softmax to convert to probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "\n",
        "      # Sample from the distribution\n",
        "      idx_next = torch.multinomial (probs, num_samples=1) # (B, 1)\n",
        "\n",
        "      # Append sampled index to the running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# 0 = newline character aka start a sequence\n",
        "idx = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MerzFB2QMHQw",
        "outputId": "91f93ad0-38cd-4f51-b608-a58d14250273"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 103])\n",
            "tensor(5.3432, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "pnC–úyaɛBgíYpH(I–,êOúxïZkQG,¿Súg5A2Só[ɛ.g2NxyAFG6GGvé1&5¿L\n",
            "ykọM;DNw–\"ɲWé[¿D]]9–4è87qYQ;,KbvnkDèR!2g\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's train the model so it's less random"
      ],
      "metadata": {
        "id": "Ja2VT_2wHGmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "# Learning rate of 1e-4 is normal, but this is a super tiny network so we can use a higher learning rate\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "a3DDNNwyMFhn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "for steps in range(100):\n",
        "  # Sample a batch of data\n",
        "  xb, yb, get_batch('train')\n",
        "\n",
        "  # evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(loss.item())\n",
        "\n",
        "# 0 = newline character aka start a sequence\n",
        "idx = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdilkC7LLkq-",
        "outputId": "f2a44774-1197-4852-ba2f-17e77de6a2e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.343222618103027\n",
            "5.3412346839904785\n",
            "5.339247703552246\n",
            "5.337258815765381\n",
            "5.33527135848999\n",
            "5.333284378051758\n",
            "5.331296443939209\n",
            "5.329308986663818\n",
            "5.327322006225586\n",
            "5.3253350257873535\n",
            "5.323347568511963\n",
            "5.321361064910889\n",
            "5.31937313079834\n",
            "5.317386627197266\n",
            "5.315399646759033\n",
            "5.313413143157959\n",
            "5.311426639556885\n",
            "5.309439659118652\n",
            "5.307453155517578\n",
            "5.305467128753662\n",
            "5.303481101989746\n",
            "5.301494121551514\n",
            "5.299508094787598\n",
            "5.297521591186523\n",
            "5.295535564422607\n",
            "5.29355001449585\n",
            "5.291564464569092\n",
            "5.289578437805176\n",
            "5.287593364715576\n",
            "5.28560733795166\n",
            "5.283621788024902\n",
            "5.281635761260986\n",
            "5.279650688171387\n",
            "5.277666091918945\n",
            "5.275681018829346\n",
            "5.273695468902588\n",
            "5.271711349487305\n",
            "5.269725799560547\n",
            "5.267741680145264\n",
            "5.265756607055664\n",
            "5.263772487640381\n",
            "5.261787414550781\n",
            "5.259803771972656\n",
            "5.257819175720215\n",
            "5.255836009979248\n",
            "5.253850936889648\n",
            "5.251867294311523\n",
            "5.24988317489624\n",
            "5.247899055480957\n",
            "5.24591588973999\n",
            "5.243932723999023\n",
            "5.241949081420898\n",
            "5.239965438842773\n",
            "5.237982273101807\n",
            "5.235998630523682\n",
            "5.234015941619873\n",
            "5.232032775878906\n",
            "5.2300496101379395\n",
            "5.228067398071289\n",
            "5.226085186004639\n",
            "5.22410249710083\n",
            "5.2221198081970215\n",
            "5.220137596130371\n",
            "5.2181549072265625\n",
            "5.216172695159912\n",
            "5.214190483093262\n",
            "5.212208271026611\n",
            "5.210227012634277\n",
            "5.208244800567627\n",
            "5.206263542175293\n",
            "5.204281330108643\n",
            "5.202300071716309\n",
            "5.200318336486816\n",
            "5.198337554931641\n",
            "5.196356296539307\n",
            "5.194375038146973\n",
            "5.192393779754639\n",
            "5.190413475036621\n",
            "5.188432216644287\n",
            "5.1864519119262695\n",
            "5.18447208404541\n",
            "5.182491779327393\n",
            "5.180511474609375\n",
            "5.178531169891357\n",
            "5.176550388336182\n",
            "5.174570560455322\n",
            "5.172590732574463\n",
            "5.1706109046936035\n",
            "5.168630123138428\n",
            "5.166651248931885\n",
            "5.164671897888184\n",
            "5.162692546844482\n",
            "5.160713195800781\n",
            "5.15873384475708\n",
            "5.156754493713379\n",
            "5.154775619506836\n",
            "5.152796745300293\n",
            "5.15081787109375\n",
            "5.148839473724365\n",
            "5.1468610763549805\n",
            "\n",
            "kH![Wj6!eDOS]TXhzs1ykTG3óz7ɲoa(:p!A7ẹ9í.ñnóc7kf i.ñfPhz\n",
            "kMdádɛ9Róú3ÉK3ɛ2íS\n",
            "yviVá/̀óJ]To?\n",
            "6ɔɛHHoJ\n",
            "—ɲR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Run 1,000 times and show the prediction at the end\n"
      ],
      "metadata": {
        "id": "U1qxAU47Imal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 32\n",
        "\n",
        "for steps in range(1000):\n",
        "  # Sample a batch of data\n",
        "  xb, yb, get_batch('train')\n",
        "\n",
        "  # evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(loss.item())\n",
        "\n",
        "# 0 = newline character aka start a sequence\n",
        "idx = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjoxje-NIkdH",
        "outputId": "fd0d4421-0afe-4989-f3e7-0f2513a47e15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2641074657440186\n",
            "\n",
            "ẹ:k!9/[UúN7oỌp̀G6ẹ–ẹZvDñ6fèzJ\"vọkGDEuɔât'Oè3/âvàq8áPẹ(.)í\n",
            "]D—-umàB,pọFỌ7ẹi?AbDɛ.O1/ɛñ3ẀWC¿JCcz0dA–b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run 10,000 times"
      ],
      "metadata": {
        "id": "4IqwJ4XLI2ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "for steps in range(10000):\n",
        "  # Sample a batch of data\n",
        "  xb, yb, get_batch('train')\n",
        "\n",
        "  # evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(loss.item())\n",
        "\n",
        "# 0 = newline character aka start a sequence\n",
        "idx = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDjLMrJ-IzXm",
        "outputId": "12200321-a8be-4664-e186-f287a6313044"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.533035397529602\n",
            "\n",
            "EvergergergetJP4Z:ɛ, okay\n",
            "Evergerget it oft wherget ofEvet wherget it it y\n",
            "Evet ou\n",
            "Okasssssss ou\n",
            "Oka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = newline character aka start a sequence\n",
        "idx = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eycHgbyLmUG",
        "outputId": "e3b68be0-cc9e-478e-9582-62d1758dc8b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Okayokay\n",
            "Everget whet whet it you\n",
            "Okass okay\n",
            "Evet it y\n",
            "Okassss yokas okayofIá'hergerget of.t whet ou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target"
      ],
      "metadata": {
        "id": "sOxsyngmLpOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "kVSqcIOtLm-u",
        "outputId": "78af05ca-4f62-4b64-b62f-cc1690e92413"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1d0c55b29c9f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len() of a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9pb9UgTKzHT",
        "outputId": "f0bfb6ae-39ee-4e6c-e08e-03c2bd368f55"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "context_list = context.tolist()\n",
        "type(context_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CcLTd5uK1nj",
        "outputId": "41b0dc63-a350-4644-b9c3-3bdacdccc915"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "[decode(x) for x in context]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "zUj-CwjwKvxZ",
        "outputId": "0ce5fd33-955e-4488-d3db-922d16598561"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a51cddedbfec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-a51cddedbfec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-a8ee4bfed58b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Decoder: Given a liste of integers, convert it to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_to_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hii there'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# See gh-54457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iteration over a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEZC9VAVKboY",
        "outputId": "92f8ad3a-0bb3-4fd1-9591-cb814b1a9a28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-6-a8ee4bfed58b>\u001b[0m(10)\u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      9 \u001b[0;31m\u001b[0;31m# Decoder: Given a liste of integers, convert it to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m\u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_to_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     11 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hii there'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> dir()\n",
            "['l']\n",
            "ipdb> print(l)\n",
            "71\n",
            "ipdb> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 361, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN4TK3IoKfs4",
        "outputId": "b993102d-afa1-4cef-b7d2-b00683aca166"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg5psjy6KIFF",
        "outputId": "10b3961d-f6dd-4e8f-95c6-9bdd6b5f3a47"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-6-a8ee4bfed58b>\u001b[0m(10)\u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      9 \u001b[0;31m\u001b[0;31m# Decoder: Given a liste of integers, convert it to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m\u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_to_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     11 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hii there'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> dir()\n",
            "['l']\n",
            "ipdb> i\n",
            "*** NameError: name 'i' is not defined\n",
            "ipdb> l\n",
            "\u001b[1;32m      5 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      6 \u001b[0m\u001b[0;31m# Encoder: Take a string and convert it to integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      7 \u001b[0m\u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms_to_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      9 \u001b[0m\u001b[0;31m# Decoder: Given a liste of integers, convert it to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 10 \u001b[0;31m\u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_to_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     11 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     12 \u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hii there'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     13 \u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hii there'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "ipdb> d\n",
            "*** Newest frame\n",
            "ipdb> u\n",
            "> \u001b[0;32m<ipython-input-15-f17c52805b6c>\u001b[0m(31)\u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     28 \u001b[0;31m    \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     29 \u001b[0;31m    \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     30 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"when input is {context.tolist()}, the target: {target}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 31 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"when input is {[decode(x) for x in context.tolist()]}, the target: {decode(target)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> print(l)\n",
            "*** NameError: name 'l' is not defined\n",
            "ipdb> context\n",
            "*** The 'context' command requires a positive integer argument.\n",
            "ipdb> context.tolist()\n",
            "*** The 'context' command requires a positive integer argument.\n",
            "ipdb> c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 347, in set_continue\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "DzKnNkD-KON3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}